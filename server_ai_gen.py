#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI ê¸°ë°˜ ê·¼ë¬´í‘œ ìƒì„± ì„œë²„ (server_ai_gen.py)
OR-Tools ëŒ€ì‹  OpenAI GPT-4ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜„ì‹¤ì ì´ê³  ìœ ì—°í•œ ê·¼ë¬´í‘œ ìƒì„±
ê¸°ì¡´ í”„ë¡œí† ì½œê³¼ ì œì•½ì‚¬í•­ ì™„ì „ í˜¸í™˜
"""

import os
import sys
import socket
import json
import struct
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
import threading
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["PYTHONUNBUFFERED"] = "1"

# stdout/stderrì„ line-bufferedë¡œ ê°•ì œ ì¬ë°”ì¸ë”©
sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1, encoding='utf-8', errors='replace')
sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1, encoding='utf-8', errors='replace')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)

logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„œë²„ ì„¤ì •
HOST = '0.0.0.0'
PORT = 6004
MAX_PACKET_SIZE = 10 * 1024 * 1024  # 10MB

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
openai_client = None
OPENAI_AVAILABLE = False

try:
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    if OPENAI_API_KEY:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        OPENAI_AVAILABLE = True
        logger.info("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    else:
        logger.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
except Exception as e:
    logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# =============================================================================
# OpenAI ê¸°ë°˜ ê·¼ë¬´í‘œ ìƒì„± í´ë˜ìŠ¤
# =============================================================================

class AIShiftGenerator:
    def __init__(self):
        self.model = "gpt-3.5-turbo"  # GPT-4 â†’ GPT-3.5-turboë¡œ ë³€ê²½ (ì†ë„ í–¥ìƒ)
        self.max_retries = 3
        
    def generate_shift_schedule(self, staff_data: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¼ë¬´í‘œ ìƒì„±"""
        if not OPENAI_AVAILABLE:
            return {
                "status": "error",
                "message": "OpenAI APIê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤"
            }
        
        try:
            # ì§ì› ì •ë³´ ì¶”ì¶œ
            staff_list = staff_data.get('staff', [])
            position = staff_data.get('position', 'ê°„í˜¸')
            target_year = staff_data.get('target_year', datetime.now().year)
            target_month = staff_data.get('target_month', datetime.now().month)
            
            # ì›”ë³„ ì¼ìˆ˜ ê³„ì‚°
            if target_month == 2:
                # ìœ¤ë…„ ì²´í¬
                is_leap = (target_year % 4 == 0 and target_year % 100 != 0) or (target_year % 400 == 0)
                days_in_month = 29 if is_leap else 28
            elif target_month in [4, 6, 9, 11]:
                days_in_month = 30
            else:
                days_in_month = 31
            
            logger.info(f"ğŸ¤– OpenAI ê·¼ë¬´í‘œ ìƒì„± ì‹œì‘: {len(staff_list)}ëª…, {position}, {target_year}ë…„ {target_month}ì›” ({days_in_month}ì¼)")
            
            # OpenAI í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_schedule_prompt(staff_list, position, days_in_month, target_year, target_month)
            
            # OpenAI API í˜¸ì¶œ
            for attempt in range(self.max_retries):
                try:
                    logger.info(f"ğŸ”„ OpenAI API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}")
                    
                    response = openai_client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {
                                "role": "system",
                                "content": """ë‹¹ì‹ ì€ ë³‘ì› ê·¼ë¬´í‘œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                                ìš”ì²­ë°›ì€ ê·¼ë¬´í‘œë¥¼ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
                                ì ˆëŒ€ë¡œ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
                                ì˜¤ì§ ìœ íš¨í•œ JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
                            },
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        max_tokens=3000,  # í† í° ìˆ˜ ì•½ê°„ ì¤„ì„ (ì†ë„ í–¥ìƒ)
                        temperature=0.1   # ë” ì¼ê´€ëœ ì¶œë ¥ (ì†ë„ í–¥ìƒ)
                    )
                    
                    # ì‘ë‹µ íŒŒì‹±
                    ai_response = response.choices[0].message.content.strip()
                    logger.info(f"âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ ({len(ai_response)} ë¬¸ì)")
                    
                    # JSON ì¶”ì¶œ ë° íŒŒì‹±
                    schedule_data = self._parse_ai_response(ai_response)
                    
                    if schedule_data:
                        # 3ì¼ íŒ¨í„´ì„ 31ì¼ë¡œ í™•ì¥
                        extended_schedule = self._extend_schedule_pattern(schedule_data, days_in_month)
                        
                        logger.info("âœ… OpenAI ê·¼ë¬´í‘œ ìƒì„± ì„±ê³µ")
                        return {
                            "status": "success",
                            "schedule": extended_schedule,
                            "ai_response": ai_response,
                            "generation_method": "openai_gpt35_pattern",
                            "attempt": attempt + 1
                        }
                    else:
                        logger.warning(f"âš ï¸ ì‹œë„ {attempt + 1}: JSON íŒŒì‹± ì‹¤íŒ¨")
                        
                except Exception as e:
                    logger.error(f"âŒ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                    if attempt == self.max_retries - 1:
                        raise
                    
                    time.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
            
            return {
                "status": "error",
                "message": f"{self.max_retries}ë²ˆ ì‹œë„ í›„ ì‹¤íŒ¨"
            }
            
        except Exception as e:
            logger.error(f"âŒ OpenAI ê·¼ë¬´í‘œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "message": f"OpenAI ê·¼ë¬´í‘œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            }
    
    def _create_schedule_prompt(self, staff_list: List[Dict], position: str, days_in_month: int, year: int, month: int) -> str:
        """OpenAIìš© ê·¼ë¬´í‘œ ìƒì„± í”„ë¡¬í”„íŠ¸ ì‘ì„±"""
        
        # ì§ì› ì •ë³´ ì •ë¦¬
        staff_names = []
        for staff in staff_list:
            name = staff.get('name', f"ì§ì›{staff.get('staff_id', 'Unknown')}")
            staff_id = staff.get('staff_id', 0)
            grade = staff.get('grade', 4)
            total_hours = staff.get('total_hours', 180)
            staff_names.append(f"{name}(ID:{staff_id}, ë“±ê¸‰:{grade}, ìµœëŒ€:{total_hours}h)")
        
        prompt = f"""ë‹¹ì‹ ì€ ë³‘ì› ê·¼ë¬´í‘œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì¡°ê±´ì— ë§ëŠ” ê·¼ë¬´í‘œë¥¼ JSONìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

=== ê·¼ë¬´í‘œ ì •ë³´ ===
- ê¸°ê°„: {year}ë…„ {month}ì›” (ì´ {days_in_month}ì¼)
- ì§ì›: {len(staff_list)}ëª…
- êµëŒ€: Day(8h), Evening(8h), Night(8h) - ê° êµëŒ€ë§ˆë‹¤ 1ëª…ì”© ë°°ì •

=== ì§ì› ì •ë³´ ===
{chr(10).join(staff_names)}

=== ì œì•½ì¡°ê±´ ===
1. ê° ë‚ ì§œì˜ Day, Evening, Nightì— ë°˜ë“œì‹œ 1ëª…ì”© ë°°ì •
2. âš ï¸ ì‹ ì…ê°„í˜¸ì‚¬(grade 5)ëŠ” í˜¼ì ì•¼ê°„ê·¼ë¬´ ê¸ˆì§€ - Night êµëŒ€ì— í˜¼ì ë°°ì • ì•ˆë¨ (ì„ ë°°ì™€ í•¨ê»˜ë©´ ê°€ëŠ¥)
3. Night ê·¼ë¬´ í›„ ë‹¤ìŒë‚  ë°˜ë“œì‹œ íœ´ë¬´
4. ì—°ì† ê·¼ë¬´ëŠ” ìµœëŒ€ 3ì¼
5. 160ì‹œê°„ ì œí•œ ì¤€ìˆ˜ (ìµœëŒ€ 20ì¼ ê·¼ë¬´)
6. í˜•í‰ì„±: ì§ì›ê°„ ê·¼ë¬´ì¼ ì°¨ì´ ìµœì†Œí™”

=== ì¶œë ¥ í˜•ì‹ ===
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "schedule": [
    {{"day": 0, "shift": "Day", "hours": 8, "people": [{{"name": "ê¹€ê°„í˜¸ì‚¬", "staff_id": 1, "grade": 3}}]}},
    {{"day": 0, "shift": "Evening", "hours": 8, "people": [{{"name": "ì´ê°„í˜¸ì‚¬", "staff_id": 2, "grade": 4}}]}},
    {{"day": 0, "shift": "Night", "hours": 8, "people": [{{"name": "ë°•ê°„í˜¸ì‚¬", "staff_id": 3, "grade": 4}}]}},
    {{"day": 1, "shift": "Day", "hours": 8, "people": [{{"name": "ìµœê°„í˜¸ì‚¬", "staff_id": 4, "grade": 3}}]}},
    {{"day": 1, "shift": "Evening", "hours": 8, "people": [{{"name": "ì •ê°„í˜¸ì‚¬", "staff_id": 5, "grade": 5}}]}},
    {{"day": 1, "shift": "Night", "hours": 8, "people": [{{"name": "í•œê°„í˜¸ì‚¬", "staff_id": 6, "grade": 4}}]}},
    {{"day": 2, "shift": "Day", "hours": 8, "people": [{{"name": "ì¥ê°„í˜¸ì‚¬", "staff_id": 7, "grade": 3}}]}},
    {{"day": 2, "shift": "Evening", "hours": 8, "people": [{{"name": "ìœ¤ê°„í˜¸ì‚¬", "staff_id": 8, "grade": 4}}]}},
    {{"day": 2, "shift": "Night", "hours": 8, "people": [{{"name": "ê°•ê°„í˜¸ì‚¬", "staff_id": 9, "grade": 4}}]}},
    {{"day": 3, "shift": "Day", "hours": 8, "people": [{{"name": "ì¡°ê°„í˜¸ì‚¬", "staff_id": 10, "grade": 3}}]}},
    {{"day": 3, "shift": "Evening", "hours": 8, "people": [{{"name": "ê¹€ê°„í˜¸ì‚¬", "staff_id": 1, "grade": 3}}]}},
    {{"day": 3, "shift": "Night", "hours": 8, "people": [{{"name": "ì´ê°„í˜¸ì‚¬", "staff_id": 2, "grade": 4}}]}}
  ],
  "fairness_analysis": {{
    "max_deviation": 1,
    "avg_work_days": 9.3,
    "comments": "ìµœì  íŒ¨í„´ ìƒì„± ì™„ë£Œ"
  }}
}}

ì¤‘ìš”: 
- dayëŠ” 0ë¶€í„° {days_in_month-1}ê¹Œì§€
- ì²˜ìŒ {min(len(staff_list), 10)}ì¼ì¹˜ë§Œ ìƒì„±í•˜ì„¸ìš” (í˜•í‰ì„±ì„ ìœ„í•œ ìµœì  íŒ¨í„´)
- ê° ì§ì›ì´ ê³¨ê³ ë£¨ ë°°ì¹˜ë˜ë„ë¡ ìˆœí™˜ íŒ¨í„´ ë§Œë“¤ê¸°
- âš ï¸ grade 5 ì‹ ì…ê°„í˜¸ì‚¬ê°€ Night êµëŒ€ì— í˜¼ì ë°°ì •ë˜ì§€ ì•Šë„ë¡ ì£¼ì˜
- JSONì— ì£¼ì„(//), ì„¤ëª…, ìƒëµ(...) ì ˆëŒ€ í¬í•¨ ê¸ˆì§€
- ì™„ì „í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”"""
        
        return prompt
    
    def _extend_schedule_pattern(self, base_schedule: List[Dict], days_in_month: int) -> List[Dict]:
        """ì ì‘ì  íŒ¨í„´ì„ ì „ì²´ ì›”ë¡œ í™•ì¥"""
        if not base_schedule:
            return []
        
        extended_schedule = []
        
        # ì‹¤ì œ íŒ¨í„´ ê¸¸ì´ í™•ì¸ (AIê°€ ìƒì„±í•œ ì¼ìˆ˜)
        pattern_days = max([entry.get("day", 0) for entry in base_schedule]) + 1
        entries_per_day = 3  # Day, Evening, Night
        
        logger.info(f"ğŸ“… ê°ì§€ëœ íŒ¨í„´ ê¸¸ì´: {pattern_days}ì¼")
        
        for target_day in range(days_in_month):
            pattern_day = target_day % pattern_days
            
            # í•´ë‹¹ íŒ¨í„´ ë‚ ì§œì˜ ëª¨ë“  êµëŒ€ ì°¾ê¸°
            for shift_type in ["Day", "Evening", "Night"]:
                # íŒ¨í„´ì—ì„œ í•´ë‹¹í•˜ëŠ” ì—”íŠ¸ë¦¬ ì°¾ê¸°
                pattern_entry = None
                for entry in base_schedule:
                    if entry.get("day") == pattern_day and entry.get("shift") == shift_type:
                        pattern_entry = entry
                        break
                
                if pattern_entry:
                    # ìƒˆ ì—”íŠ¸ë¦¬ ìƒì„± (ë‚ ì§œë§Œ ë³€ê²½)
                    new_entry = {
                        "day": target_day,
                        "shift": shift_type,
                        "hours": pattern_entry.get("hours", 8),
                        "people": pattern_entry.get("people", []).copy()
                    }
                    extended_schedule.append(new_entry)
        
        logger.info(f"ğŸ“… íŒ¨í„´ í™•ì¥ ì™„ë£Œ: {len(base_schedule)}ê°œ â†’ {len(extended_schedule)}ê°œ ì—”íŠ¸ë¦¬")
        return extended_schedule
    
    def _parse_ai_response(self, ai_response: str) -> Optional[List[Dict]]:
        """OpenAI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±"""
        try:
            # ì‘ë‹µ ì •ë¦¬ (ê³µë°±, ì¤„ë°”ê¿ˆ ì œê±°)
            cleaned_response = ai_response.strip()
            
            # JSON ë¸”ë¡ ì°¾ê¸° (```json íƒœê·¸ ê³ ë ¤)
            if "```json" in cleaned_response:
                json_start = cleaned_response.find('{', cleaned_response.find('```json'))
                json_end = cleaned_response.rfind('}', 0, cleaned_response.find('```', cleaned_response.find('```json') + 7))
                if json_end != -1:
                    json_end += 1
            else:
                json_start = cleaned_response.find('{')
                json_end = cleaned_response.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                logger.error("âŒ AI ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                logger.error(f"ì‘ë‹µ ë‚´ìš©: {cleaned_response[:200]}...")
                return None
            
            json_str = cleaned_response[json_start:json_end]
            logger.info(f"ğŸ“‹ ì¶”ì¶œëœ JSON ê¸¸ì´: {len(json_str)} ë¬¸ì")
            
            schedule_data = json.loads(json_str)
            
            # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
            if 'schedule' not in schedule_data:
                logger.error("âŒ AI ì‘ë‹µì— 'schedule' í‚¤ê°€ ì—†ìŒ")
                return None
            
            schedule = schedule_data['schedule']
            if not isinstance(schedule, list) or len(schedule) == 0:
                logger.error("âŒ ìŠ¤ì¼€ì¤„ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜ëª»ëœ í˜•ì‹")
                return None
            
            # í˜•í‰ì„± ë¶„ì„ ë¡œê·¸
            if 'fairness_analysis' in schedule_data:
                fairness = schedule_data['fairness_analysis']
                logger.info(f"ğŸ“Š AI í˜•í‰ì„± ë¶„ì„: ìµœëŒ€í¸ì°¨ {fairness.get('max_deviation', 'Unknown')}ì¼, "
                           f"í‰ê·  ê·¼ë¬´ì¼ {fairness.get('avg_work_days', 'Unknown')}ì¼")
            
            # ì œì•½ì¡°ê±´ ì¤€ìˆ˜ ë¡œê·¸  
            if 'constraints_status' in schedule_data:
                constraints = schedule_data['constraints_status']
                logger.info(f"âœ… ì œì•½ì¡°ê±´ ì¤€ìˆ˜: ì‹œê°„ì œí•œ {constraints.get('hours_limit_compliance', False)}, "
                           f"í˜•í‰ì„± {constraints.get('fairness_achieved', False)}")
            
            return schedule
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            logger.error(f"ë¬¸ì œê°€ ëœ ì‘ë‹µ: {ai_response[:500]}...")
            return None
        except Exception as e:
            logger.error(f"âŒ AI ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜ˆì™¸: {e}")
            return None

# =============================================================================
# ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” í´ë˜ìŠ¤
# =============================================================================

class AIHandoverEnhancer:
    def __init__(self):
        self.model = "gpt-3.5-turbo"
    
    def enhance_handover_text(self, input_text: str) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ì¸ìˆ˜ì¸ê³„ ë¬¸ì¥ ëª…ë£Œí™”"""
        if not OPENAI_AVAILABLE:
            return {
                "status": "error",
                "message": "OpenAI APIê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤",
                "original_text": input_text,
                "enhanced_text": input_text
            }
        
        start_time = time.time()
        
        try:
            if not input_text or input_text.strip() == "":
                return {
                    "status": "error",
                    "message": "ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤",
                    "original_text": input_text,
                    "enhanced_text": input_text
                }
            
            logger.info(f"ğŸ“ ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ì‹œì‘: {len(input_text)} ë¬¸ì")
            
            system_prompt = """ë‹¹ì‹ ì€ ë³‘ì› ê°„í˜¸ì‚¬ë“¤ì˜ ì¸ìˆ˜ì¸ê³„ ë¬¸ì¥ì„ ëª…ë£Œí•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            
            ì˜ë£Œì§„ì´ ë¹ ë¥´ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡:
            1. í•µì‹¬ ì •ë³´ë¥¼ ì•ìª½ì— ë°°ì¹˜
            2. ì¤‘ìš”ë„ì— ë”°ë¼ ìš°ì„ ìˆœìœ„ ì •ë¦¬
            3. ë¶ˆí•„ìš”í•œ ë§ì€ ìƒëµí•˜ê³  ê°„ê²°í•˜ê²Œ
            4. ì˜ë£Œ ìš©ì–´ëŠ” ì •í™•í•˜ê²Œ ì‚¬ìš©
            5. ì‹œê¸‰í•œ ì‚¬í•­ì€ ëª…í™•íˆ í‘œì‹œ
            
            ì ˆëŒ€ ** ê°™ì€ ê¸°í˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""
            
            response = openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ ì¸ìˆ˜ì¸ê³„ ë‚´ìš©ì„ ë” ëª…ë£Œí•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”:\n\n{input_text}"}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            enhanced_text = response.choices[0].message.content.strip()
            process_time = time.time() - start_time
            
            logger.info(f"âœ… ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ì™„ë£Œ: {process_time:.2f}ì´ˆ, {len(enhanced_text)} ë¬¸ì")
            
            return {
                "status": "success",
                "original_text": input_text,
                "enhanced_text": enhanced_text,
                "processing_time": process_time,
                "model_used": self.model
            }
            
        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"âŒ ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ì‹¤íŒ¨ ({process_time:.2f}ì´ˆ): {e}")
            
            return {
                "status": "error",
                "message": f"ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ì¤‘ ì˜¤ë¥˜: {str(e)}",
                "original_text": input_text,
                "enhanced_text": input_text,
                "processing_time": process_time
            }

# =============================================================================
# ë°”ì´ë„ˆë¦¬ í”„ë¡œí† ì½œ í•¸ë“¤ëŸ¬ (ê¸°ì¡´ê³¼ ë™ì¼)
# =============================================================================

class BinaryProtocolHandler:
    """C++ í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ ë°”ì´ë„ˆë¦¬ í”„ë¡œí† ì½œ í•¸ë“¤ëŸ¬"""
    
    @staticmethod
    def recv_exact(conn: socket.socket, n: int) -> bytes:
        """ì •í™•íˆ në°”ì´íŠ¸ ìˆ˜ì‹ """
        conn.settimeout(10.0)
        buf = b''
        while len(buf) < n:
            chunk = conn.recv(n - len(buf))
            if not chunk:
                raise ConnectionError(f"Socket connection closed unexpectedly")
            buf += chunk
        return buf
    
    @staticmethod
    def receive_packet(conn: socket.socket) -> Optional[Dict[str, Any]]:
        """ë°”ì´ë„ˆë¦¬ í”„ë¡œí† ì½œë¡œ íŒ¨í‚· ìˆ˜ì‹ """
        try:
            # 8ë°”ì´íŠ¸ í—¤ë” ì½ê¸°
            header = BinaryProtocolHandler.recv_exact(conn, 8)
            
            # ë¦¬í‹€ì—”ë””ì•ˆìœ¼ë¡œ í—¤ë” íŒŒì‹±
            total_size = struct.unpack('<I', header[:4])[0]
            json_size = struct.unpack('<I', header[4:8])[0]
            
            logger.info(f"ğŸ“¦ í—¤ë”: totalSize={total_size}, jsonSize={json_size}")
            
            # í¬ê¸° ê²€ì¦
            if json_size == 0 or json_size > total_size or total_size > MAX_PACKET_SIZE:
                logger.error(f"âŒ ì˜ëª»ëœ í—¤ë”: jsonSize={json_size}, totalSize={total_size}")
                return None
            
            # JSON ë°ì´í„° ì½ê¸°
            json_data = BinaryProtocolHandler.recv_exact(conn, json_size).decode('utf-8')
            request = json.loads(json_data)
            
            logger.info(f"ğŸ“¨ ìš”ì²­ ìˆ˜ì‹ : {request.get('protocol', 'unknown')}")
            return request
            
        except Exception as e:
            logger.error(f"âŒ íŒ¨í‚· ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
            return None
    
    @staticmethod
    def send_response(conn: socket.socket, response: Dict[str, Any]) -> bool:
        """ë°”ì´ë„ˆë¦¬ í”„ë¡œí† ì½œë¡œ ì‘ë‹µ ì „ì†¡"""
        try:
            # JSON ì§ë ¬í™”
            response_json = json.dumps(response, ensure_ascii=False)
            response_bytes = response_json.encode('utf-8')
            
            json_size = len(response_bytes)
            total_size = 8 + json_size
            
            # ë¦¬í‹€ì—”ë””ì•ˆ í—¤ë” ìƒì„±
            header = struct.pack('<II', total_size, json_size)
            
            # í—¤ë” + JSON ì „ì†¡
            conn.sendall(header + response_bytes)
            
            logger.info(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡: {total_size}ë°”ì´íŠ¸")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ ì „ì†¡ ì˜¤ë¥˜: {e}")
            return False

# =============================================================================
# ë©”ì¸ ì„œë²„ í´ë˜ìŠ¤
# =============================================================================

class AIShiftSchedulerServer:
    def __init__(self, host: str = HOST, port: int = PORT):
        self.host = host
        self.port = port
        self.running = False
        self.ai_generator = AIShiftGenerator()
        self.ai_enhancer = AIHandoverEnhancer()
        
        logger.info(f"ğŸ¤– AI ê¸°ë°˜ ê·¼ë¬´í‘œ ì„œë²„ ì´ˆê¸°í™”: {host}:{port}")
    
    def start(self):
        """ì„œë²„ ì‹œì‘"""
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:
            server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            server_socket.bind((self.host, self.port))
            server_socket.listen(5)
            
            self.running = True
            logger.info(f"ğŸš€ AI ê·¼ë¬´í‘œ ì„œë²„ ì‹œì‘: {self.host}:{self.port}")
            logger.info("ğŸ“ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŒ€ê¸° ì¤‘...")
            
            while self.running:
                try:
                    conn, addr = server_socket.accept()
                    logger.info(f"ğŸ”— í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {addr}")
                    
                    # ê° í´ë¼ì´ì–¸íŠ¸ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬
                    client_thread = threading.Thread(
                        target=self.handle_client,
                        args=(conn, addr)
                    )
                    client_thread.daemon = True
                    client_thread.start()
                    
                except Exception as e:
                    logger.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ë½ ì˜¤ë¥˜: {e}")
    
    def handle_client(self, conn: socket.socket, addr):
        """í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ì²˜ë¦¬"""
        try:
            # ìš”ì²­ ìˆ˜ì‹ 
            request = BinaryProtocolHandler.receive_packet(conn)
            if not request:
                return
            
            # í”„ë¡œí† ì½œë³„ ì²˜ë¦¬
            protocol = request.get('protocol', '')
            
            if protocol in ['py_gen_timetable', 'py_gen_schedule']:
                response = self.handle_schedule_request(request)
            elif protocol == 'py_handover_summary':
                response = self.handle_handover_request(request)
            else:
                logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡œí† ì½œ: {protocol}")
                response = {
                    'protocol': protocol,
                    'resp': 'error',
                    'data': {'error': f'Unknown protocol: {protocol}'}
                }
            
            # ì‘ë‹µ ì „ì†¡
            BinaryProtocolHandler.send_response(conn, response)
            logger.info("âœ… ì‘ë‹µ ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        finally:
            conn.close()
            logger.info(f"ğŸ”Œ {addr} ì—°ê²° ì¢…ë£Œ")
    
    def handle_schedule_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ê·¼ë¬´í‘œ ìƒì„± ìš”ì²­ ì²˜ë¦¬"""
        try:
            start_time = time.time()
            logger.info("ğŸ¤– AI ê·¼ë¬´í‘œ ìƒì„± ìš”ì²­ ì²˜ë¦¬ ì‹œì‘")
            
            # ìš”ì²­ ë°ì´í„° ì¶”ì¶œ
            data = request.get('data', {})
            
            # OpenAIë¡œ ê·¼ë¬´í‘œ ìƒì„±
            result = self.ai_generator.generate_shift_schedule(data)
            
            processing_time = time.time() - start_time
            
            if result.get('status') == 'success':
                logger.info(f"âœ… AI ê·¼ë¬´í‘œ ìƒì„± ì„±ê³µ ({processing_time:.2f}ì´ˆ)")
                
                return {
                    'protocol': request.get('protocol'),
                    'resp': 'success',
                    'data': {
                        'schedule': result['schedule'],
                        'generation_method': 'openai_ai',
                        'processing_time': processing_time,
                        'ai_metadata': {
                            'model_used': self.ai_generator.model,
                            'attempt': result.get('attempt', 1),
                            'has_fairness_analysis': 'fairness_analysis' in result
                        }
                    }
                }
            else:
                logger.error(f"âŒ AI ê·¼ë¬´í‘œ ìƒì„± ì‹¤íŒ¨: {result.get('message', 'Unknown error')}")
                
                return {
                    'protocol': request.get('protocol'),
                    'resp': 'error',
                    'data': {
                        'error': result.get('message', 'AI schedule generation failed'),
                        'processing_time': processing_time
                    }
                }
                
        except Exception as e:
            logger.error(f"âŒ ê·¼ë¬´í‘œ ìš”ì²­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                'protocol': request.get('protocol'),
                'resp': 'error',
                'data': {'error': str(e)}
            }
    
    def handle_handover_request(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ìš”ì²­ ì²˜ë¦¬"""
        try:
            logger.info("ğŸ“ AI ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ìš”ì²­ ì²˜ë¦¬ ì‹œì‘")
            
            data = request.get('data', {})
            original_text = data.get('text', '')
            
            # OpenAIë¡œ ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™”
            result = self.ai_enhancer.enhance_handover_text(original_text)
            
            if result.get('status') == 'success':
                logger.info("âœ… AI ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ì„±ê³µ")
                
                return {
                    'protocol': 'py_handover_summary',
                    'resp': 'success',
                    'data': {
                        'original_text': result['original_text'],
                        'enhanced_text': result['enhanced_text'],
                        'processing_time': result.get('processing_time', 0),
                        'model_used': result.get('model_used', 'gpt-3.5-turbo')
                    }
                }
            else:
                logger.error(f"âŒ AI ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™” ì‹¤íŒ¨: {result.get('message', 'Unknown error')}")
                
                return {
                    'protocol': 'py_handover_summary',
                    'resp': 'error',
                    'data': {
                        'error': result.get('message', 'AI handover enhancement failed'),
                        'original_text': result['original_text'],
                        'enhanced_text': result['enhanced_text']
                    }
                }
                
        except Exception as e:
            logger.error(f"âŒ ì¸ìˆ˜ì¸ê³„ ìš”ì²­ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                'protocol': 'py_handover_summary',
                'resp': 'error',
                'data': {'error': str(e)}
            }
    
    def stop(self):
        """ì„œë²„ ì¤‘ì§€"""
        self.running = False
        logger.info("ğŸ›‘ ì„œë²„ ì¤‘ì§€ ìš”ì²­ë¨")

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("=" * 60)
    logger.info("ğŸ¤– AI Shift Scheduler Server v1.0")
    logger.info("=" * 60)
    logger.info("ğŸ”§ ê¸°ëŠ¥: OpenAI ê¸°ë°˜ ê·¼ë¬´í‘œ ìƒì„± + ì¸ìˆ˜ì¸ê³„ ëª…ë£Œí™”")
    logger.info("ğŸ¯ íŠ¹ì§•: í˜„ì‹¤ì ì´ê³  ìœ ì—°í•œ ê·¼ë¬´í‘œ, 160ì‹œê°„ ì œì•½ ìë™ í•´ê²°")
    logger.info("ğŸ“¡ í”„ë¡œí† ì½œ: ê¸°ì¡´ C++ í´ë¼ì´ì–¸íŠ¸ ì™„ì „ í˜¸í™˜")
    logger.info("=" * 60)
    
    # OpenAI ìƒíƒœ í™•ì¸
    if OPENAI_AVAILABLE:
        logger.info("âœ… OpenAI API ì—°ê²° í™•ì¸ë¨")
    else:
        logger.error("âŒ OpenAI API ì‚¬ìš© ë¶ˆê°€ - OPENAI_API_KEY í™•ì¸ í•„ìš”")
        logger.error("âš ï¸ ì„œë²„ë¥¼ ì‹œì‘í•˜ì§€ë§Œ AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤")
    
    # ì„œë²„ ì‹œì‘
    server = AIShiftSchedulerServer()
    
    try:
        logger.info("ğŸŒ TCP ì„œë²„ ì‹œì‘ ì¤‘...")
        server.start()
    except KeyboardInterrupt:
        logger.info("âŒ¨ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ ê°ì§€")
    except Exception as e:
        logger.error(f"âŒ ì„œë²„ ì˜¤ë¥˜: {e}")
    finally:
        server.stop()
        logger.info("ğŸ‘‹ AI ê·¼ë¬´í‘œ ì„œë²„ ì¢…ë£Œ")

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
ì¢…í•© ì„±ëŠ¥ ë° í˜•í‰ì„± í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ
- 10ëª…~30ëª… ê·œëª¨ë³„ í…ŒìŠ¤íŠ¸
- 3êµëŒ€~5êµëŒ€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸  
- ì²˜ë¦¬ ì‹œê°„, ì œì•½ì¡°ê±´ ì¤€ìˆ˜, í˜•í‰ì„± ì¢…í•© ë¶„ì„
"""

import socket
import struct
import json
import time
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
import statistics
from collections import defaultdict

class ComprehensivePerformanceTest:
    def __init__(self, host: str = "localhost", port: int = 6004):
        self.host = host
        self.port = port
        self.test_results = []
    
    def generate_staff_data(self, count: int, position: str = "ê°„í˜¸") -> List[Dict[str, Any]]:
        """ì§€ì •ëœ ìˆ˜ì˜ ì§ì› ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        staff_data = []
        
        names = [
            "ê¹€", "ì´", "ë°•", "ìµœ", "ì •", "ê°•", "ì¡°", "ìœ¤", "ì¥", "ì„",
            "í•œ", "ì˜¤", "ì„œ", "ì‹ ", "ê¶Œ", "í™©", "ì•ˆ", "ì†¡", "ë¥˜", "ì „",
            "ì§„", "ë…¸", "í•˜", "í™", "ë°°", "ì„±", "ë°±", "ì „", "ê³ ", "ë¬¸"
        ]
        
        # í˜„ì‹¤ì ì¸ ì§ê¸‰ ë¶„í¬
        if count <= 10:
            grades = [3] * (count // 3) + [2] * (count // 2) + [1] * (count - count//3 - count//2)
        elif count <= 20:
            grades = [3] * (count // 4) + [2] * (count // 2) + [1] * (count - count//4 - count//2) + [5] * (count // 10)
        else:
            grades = [3] * (count // 5) + [2] * (count // 3) + [1] * (count // 3) + [5] * (count // 10) + [4] * (count - count//5 - count//3 - count//3 - count//10)
        
        # ë¶€ì¡±í•œ ê²½ìš° 1ê¸‰ìœ¼ë¡œ ì±„ì›€
        while len(grades) < count:
            grades.append(1)
        
        for i in range(count):
            staff_data.append({
                "staff_id": 4000 + i + 1,
                "name": f"{names[i % len(names)]}{position}ì‚¬{i+1}",
                "grade": grades[i],
                "total_hours": 209,
                "position": position
            })
        
        return staff_data
    
    def get_shift_config(self, shift_type: int) -> Tuple[List[str], Dict[str, int]]:
        """êµëŒ€ ìœ í˜•ë³„ ì‹œí”„íŠ¸ êµ¬ì„±ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if shift_type == 3:
            return ["Day", "Evening", "Night", "Off"], {"Day": 8, "Evening": 8, "Night": 8, "Off": 0}
        elif shift_type == 4:
            return ["Early", "Day", "Evening", "Night", "Off"], {"Early": 8, "Day": 8, "Evening": 8, "Night": 8, "Off": 0}
        else:  # 5êµëŒ€
            return ["Early", "Day", "Late", "Evening", "Night", "Off"], {"Early": 8, "Day": 8, "Late": 8, "Evening": 8, "Night": 8, "Off": 0}
    
    def send_request_with_timing(self, request_data: Dict[str, Any]) -> Tuple[Optional[Dict[str, Any]], float]:
        """ì„œë²„ì— ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤."""
        start_time = time.time()
        
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                sock.connect((self.host, self.port))
                
                json_data = json.dumps(request_data, ensure_ascii=False)
                json_bytes = json_data.encode('utf-8')
                
                total_size = len(json_bytes)
                header = struct.pack('<II', total_size, total_size)
                
                sock.send(header + json_bytes)
                
                response_header = sock.recv(8)
                if len(response_header) < 8:
                    return None, time.time() - start_time
                
                total_size, json_size = struct.unpack('<II', response_header)
                
                response_data = b""
                while len(response_data) < json_size:
                    chunk = sock.recv(json_size - len(response_data))
                    if not chunk:
                        break
                    response_data += chunk
                
                response_time = time.time() - start_time
                return json.loads(response_data.decode('utf-8')), response_time
                
        except Exception as e:
            response_time = time.time() - start_time
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨ ({response_time:.2f}ì´ˆ): {e}")
            return None, response_time
    
    def analyze_fairness(self, schedule_data: List[Dict]) -> Dict[str, Any]:
        """ê·¼ë¬´í‘œ ë°ì´í„°ì—ì„œ í˜•í‰ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        staff_off_days = defaultdict(int)
        staff_work_days = defaultdict(int)
        staff_names = {}
        total_days = 0
        
        # ë‚ ì§œ ìˆ˜ì§‘
        dates = set()
        for entry in schedule_data:
            dates.add(entry['date'])
        total_days = len(dates)
        
        # ì§ì›ë³„ íœ´ë¬´ì¼/ê·¼ë¬´ì¼ ê³„ì‚°
        for entry in schedule_data:
            shift = entry['shift']
            for person in entry['people']:
                staff_id = person['staff_id']
                staff_names[staff_id] = person['name']
                
                if shift == 'Off':
                    staff_off_days[staff_id] += 1
                else:
                    staff_work_days[staff_id] += 1
        
        # í˜•í‰ì„± ì§€í‘œ ê³„ì‚°
        off_days_list = list(staff_off_days.values())
        if not off_days_list:
            return {"error": "No off days data found"}
        
        min_off = min(off_days_list)
        max_off = max(off_days_list)
        avg_off = statistics.mean(off_days_list)
        std_off = statistics.stdev(off_days_list) if len(off_days_list) > 1 else 0
        
        # í˜•í‰ì„± ì ìˆ˜ (0-100, ë†’ì„ìˆ˜ë¡ ê³µì •)
        fairness_score = max(0, 100 - ((max_off - min_off) * 20))  # í¸ì°¨ 1ì¼ë‹¹ 20ì  ê°ì 
        
        return {
            "total_days": total_days,
            "staff_count": len(staff_off_days),
            "min_off_days": min_off,
            "max_off_days": max_off,
            "avg_off_days": round(avg_off, 1),
            "std_off_days": round(std_off, 2),
            "range_off_days": max_off - min_off,
            "fairness_score": round(fairness_score, 1),
            "fairness_grade": self.get_fairness_grade(fairness_score),
            "staff_distribution": dict(staff_off_days)
        }
    
    def get_fairness_grade(self, score: float) -> str:
        """í˜•í‰ì„± ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if score >= 90:
            return "S+ (ì™„ë²½)"
        elif score >= 80:
            return "S (ë§¤ìš° ì–‘í˜¸)"
        elif score >= 70:
            return "A (ì–‘í˜¸)"
        elif score >= 60:
            return "B (ë³´í†µ)"
        elif score >= 50:
            return "C (ê°œì„  í•„ìš”)"
        else:
            return "D (ë¶ˆëŸ‰)"
    
    def run_single_test(self, staff_count: int, shift_type: int, month: int = 7) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {staff_count}ëª… {shift_type}êµëŒ€ ì‹œìŠ¤í…œ")
        
        staff_data = self.generate_staff_data(staff_count, "ê°„í˜¸")
        shifts, shift_hours = self.get_shift_config(shift_type)
        
        request = {
            "protocol": "py_gen_timetable",
            "data": {
                "staff_data": {
                    "staff": staff_data
                },
                "position": "ê°„í˜¸",
                "target_month": f"2025-{month:02d}",
                "custom_rules": {
                    "shifts": shifts,
                    "shift_hours": shift_hours,
                    "night_shifts": ["Night"],
                    "off_shifts": ["Off"]
                }
            }
        }
        
        response, response_time = self.send_request_with_timing(request)
        
        result = {
            "staff_count": staff_count,
            "shift_type": shift_type,
            "month": month,
            "response_time": round(response_time, 3),
            "success": False,
            "fairness_analysis": None,
            "constraint_violations": [],
            "performance_grade": "F"
        }
        
        if response and response.get("resp") == "success":
            result["success"] = True
            schedule_data = response.get("data", [])
            
            # í˜•í‰ì„± ë¶„ì„
            fairness = self.analyze_fairness(schedule_data)
            result["fairness_analysis"] = fairness
            
            # ì œì•½ì¡°ê±´ ìœ„ë°˜ ê²€ì‚¬
            violations = self.check_constraints(schedule_data, staff_data)
            result["constraint_violations"] = violations
            
            # ì¢…í•© ì„±ëŠ¥ ë“±ê¸‰
            result["performance_grade"] = self.calculate_performance_grade(response_time, fairness, violations)
            
            print(f"   âœ… ì„±ê³µ | ì‹œê°„: {response_time:.3f}ì´ˆ | í˜•í‰ì„±: {fairness['fairness_grade']} | ì„±ëŠ¥: {result['performance_grade']}")
        else:
            print(f"   âŒ ì‹¤íŒ¨ | ì‹œê°„: {response_time:.3f}ì´ˆ")
            if response:
                result["error"] = response.get("resp", "Unknown error")
        
        return result
    
    def check_constraints(self, schedule_data: List[Dict], staff_data: List[Dict]) -> List[str]:
        """ì œì•½ì¡°ê±´ ìœ„ë°˜ì‚¬í•­ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
        violations = []
        
        # ì‹ ê·œ ê°„í˜¸ì‚¬(grade 5) ì•¼ê°„ ê·¼ë¬´ ê²€ì‚¬
        newbie_ids = {staff["staff_id"] for staff in staff_data if staff.get("grade") == 5}
        
        for entry in schedule_data:
            if entry["shift"] == "Night":
                for person in entry["people"]:
                    if person["staff_id"] in newbie_ids:
                        violations.append(f"ì‹ ê·œê°„í˜¸ì‚¬ {person['name']} ì•¼ê°„ê·¼ë¬´ ìœ„ë°˜ ({entry['date']})")
        
        # TODO: ì¶”ê°€ ì œì•½ì¡°ê±´ ê²€ì‚¬ (ì—°ì† ì•¼ê°„ ê·¼ë¬´, íœ´ë¬´ í›„ ì•¼ê°„ ë“±)
        
        return violations
    
    def calculate_performance_grade(self, response_time: float, fairness: Dict, violations: List) -> str:
        """ì¢…í•© ì„±ëŠ¥ ë“±ê¸‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        score = 100
        
        # ì‘ë‹µì‹œê°„ ì ìˆ˜ (1ì´ˆ ê¸°ì¤€)
        if response_time > 2.0:
            score -= 30
        elif response_time > 1.0:
            score -= 15
        elif response_time > 0.5:
            score -= 5
        
        # í˜•í‰ì„± ì ìˆ˜ ë°˜ì˜
        fairness_score = fairness.get("fairness_score", 0)
        score = score * 0.4 + fairness_score * 0.5
        
        # ì œì•½ì¡°ê±´ ìœ„ë°˜ ê°ì 
        score -= len(violations) * 10
        
        # ë“±ê¸‰ ì‚°ì¶œ
        if score >= 90:
            return "S+"
        elif score >= 80:
            return "S"
        elif score >= 70:
            return "A"
        elif score >= 60:
            return "B"
        else:
            return "C"
    
    def run_comprehensive_tests(self):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("ğŸš€ ì‹œí”„íŠ¸ ìŠ¤ì¼€ì¤„ëŸ¬ v5.0 ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("=" * 70)
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:")
        print("  â€¢ ì§ì› ìˆ˜: 10ëª…, 15ëª…, 20ëª…, 25ëª…, 30ëª…")
        print("  â€¢ êµëŒ€ ìœ í˜•: 3êµëŒ€, 4êµëŒ€, 5êµëŒ€") 
        print("  â€¢ ì¸¡ì • í•­ëª©: ì²˜ë¦¬ì‹œê°„, í˜•í‰ì„±, ì œì•½ì¡°ê±´ ì¤€ìˆ˜")
        print("=" * 70)
        
        staff_counts = [10, 15, 20, 25, 30]
        shift_types = [3, 4, 5]
        
        start_time = time.time()
        test_number = 1
        total_tests = len(staff_counts) * len(shift_types)
        
        for staff_count in staff_counts:
            for shift_type in shift_types:
                print(f"\n[{test_number}/{total_tests}]", end=" ")
                result = self.run_single_test(staff_count, shift_type, 7)  # 7ì›” (31ì¼)
                self.test_results.append(result)
                test_number += 1
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                time.sleep(0.5)
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
        self.analyze_and_report_results(total_time)
    
    def analyze_and_report_results(self, total_time: float):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print(f"\n" + "=" * 70)
        print("ğŸ“Š ì¢…í•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        print("=" * 70)
        print(f"â±ï¸ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {total_time:.1f}ì´ˆ")
        print(f"ğŸ“‹ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(self.test_results)}ê°œ")
        
        # ì„±ê³µë¥  ê³„ì‚°
        successful_tests = [r for r in self.test_results if r["success"]]
        success_rate = len(successful_tests) / len(self.test_results) * 100
        print(f"âœ… ì„±ê³µë¥ : {success_rate:.1f}% ({len(successful_tests)}/{len(self.test_results)})")
        
        if not successful_tests:
            print("âŒ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„±ëŠ¥ ì§€í‘œ ë¶„ì„
        response_times = [r["response_time"] for r in successful_tests]
        avg_time = statistics.mean(response_times)
        min_time = min(response_times)
        max_time = max(response_times)
        
        print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„ ë¶„ì„:")
        print(f"  â€¢ í‰ê· : {avg_time:.3f}ì´ˆ")
        print(f"  â€¢ ìµœì†Œ: {min_time:.3f}ì´ˆ")  
        print(f"  â€¢ ìµœëŒ€: {max_time:.3f}ì´ˆ")
        
        # í˜•í‰ì„± ì§€í‘œ ë¶„ì„
        fairness_scores = [r["fairness_analysis"]["fairness_score"] for r in successful_tests if r.get("fairness_analysis")]
        if fairness_scores:
            avg_fairness = statistics.mean(fairness_scores)
            print(f"\nâš–ï¸ í˜•í‰ì„± ë¶„ì„:")
            print(f"  â€¢ í‰ê·  í˜•í‰ì„± ì ìˆ˜: {avg_fairness:.1f}/100")
            print(f"  â€¢ Sê¸‰ ì´ìƒ: {len([s for s in fairness_scores if s >= 80])}ê°œ")
            print(f"  â€¢ Aê¸‰ ì´ìƒ: {len([s for s in fairness_scores if s >= 70])}ê°œ")
        
        # ê·œëª¨ë³„ ì„±ëŠ¥ ë¶„ì„
        print(f"\nğŸ“ˆ ê·œëª¨ë³„ ì„±ëŠ¥ ë¶„ì„:")
        for staff_count in [10, 15, 20, 25, 30]:
            staff_results = [r for r in successful_tests if r["staff_count"] == staff_count]
            if staff_results:
                avg_time = statistics.mean([r["response_time"] for r in staff_results])
                avg_fairness = statistics.mean([r["fairness_analysis"]["fairness_score"] for r in staff_results if r.get("fairness_analysis")])
                print(f"  â€¢ {staff_count}ëª…: í‰ê·  {avg_time:.3f}ì´ˆ, í˜•í‰ì„± {avg_fairness:.1f}ì ")
        
        # êµëŒ€ë³„ ì„±ëŠ¥ ë¶„ì„
        print(f"\nğŸ”„ êµëŒ€ë³„ ì„±ëŠ¥ ë¶„ì„:")
        for shift_type in [3, 4, 5]:
            shift_results = [r for r in successful_tests if r["shift_type"] == shift_type]
            if shift_results:
                avg_time = statistics.mean([r["response_time"] for r in shift_results])
                avg_fairness = statistics.mean([r["fairness_analysis"]["fairness_score"] for r in shift_results if r.get("fairness_analysis")])
                print(f"  â€¢ {shift_type}êµëŒ€: í‰ê·  {avg_time:.3f}ì´ˆ, í˜•í‰ì„± {avg_fairness:.1f}ì ")
        
        # ìµœê³  ì„±ëŠ¥ ë° ìµœì € ì„±ëŠ¥
        best_result = max(successful_tests, key=lambda x: x.get("fairness_analysis", {}).get("fairness_score", 0))
        worst_result = min(successful_tests, key=lambda x: x.get("fairness_analysis", {}).get("fairness_score", 0))
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥:")
        print(f"  â€¢ {best_result['staff_count']}ëª… {best_result['shift_type']}êµëŒ€: {best_result['response_time']:.3f}ì´ˆ, í˜•í‰ì„± {best_result.get('fairness_analysis', {}).get('fairness_score', 0):.1f}ì ")
        
        print(f"\nğŸ“‰ ìµœì € ì„±ëŠ¥:")
        print(f"  â€¢ {worst_result['staff_count']}ëª… {worst_result['shift_type']}êµëŒ€: {worst_result['response_time']:.3f}ì´ˆ, í˜•í‰ì„± {worst_result.get('fairness_analysis', {}).get('fairness_score', 0):.1f}ì ")
        
        # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
        print(f"\nğŸ“‹ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”:")
        print("ì§ì›ìˆ˜ | êµëŒ€ | ì‹œê°„(ì´ˆ) | í˜•í‰ì„± | í¸ì°¨ | ë“±ê¸‰")
        print("-" * 45)
        for result in successful_tests:
            fa = result.get("fairness_analysis", {})
            print(f"{result['staff_count']:4d}ëª… | {result['shift_type']}êµëŒ€ | {result['response_time']:6.3f} | {fa.get('fairness_score', 0):5.1f} | {fa.get('range_off_days', 'N/A'):3} | {result['performance_grade']:2}")

if __name__ == "__main__":
    tester = ComprehensivePerformanceTest()
    tester.run_comprehensive_tests()